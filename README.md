Under the guidance of Professor Xiao, I am continuing the work done by Michale Reinisch et al. https://arxiv.org/abs/2408.10995





In brief, I have edited, added, or made siginificant changes within the following folders:
  ctp-llm/
      bert_rf : cleaned up methods, increased simulation runs to gather better evaluation metrics, tsne analysis, error analysis
      gpt_fine_tuning: fine tune gpt 4 models, started gpt-4 zero-shot/few-shot for classification
      llama_pretraining: fine tuning medical llama, standard llama, error analysis, few shot prompting, zero shot prompting
